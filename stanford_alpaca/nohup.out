WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-04-03 18:35:37,755] [INFO] [comm.py:652:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Traceback (most recent call last):
  File "/mnt/data1/namz2/taewhoo/NLP/stanford_alpaca/train.py", line 231, in <module>
Traceback (most recent call last):
  File "/mnt/data1/namz2/taewhoo/NLP/stanford_alpaca/train.py", line 231, in <module>
    train()    
train()
  File "/mnt/data1/namz2/taewhoo/NLP/stanford_alpaca/train.py", line 194, in train
  File "/mnt/data1/namz2/taewhoo/NLP/stanford_alpaca/train.py", line 194, in train
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/transformers/hf_argparser.py", line 332, in parse_args_into_dataclasses
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/transformers/hf_argparser.py", line 332, in parse_args_into_dataclasses
        obj = dtype(**inputs)obj = dtype(**inputs)

  File "<string>", line 111, in __init__
  File "<string>", line 111, in __init__
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/transformers/training_args.py", line 1224, in __post_init__
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/transformers/training_args.py", line 1224, in __post_init__
    and (self.device.type != "cuda")
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/transformers/training_args.py", line 1656, in device
    and (self.device.type != "cuda")
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/transformers/training_args.py", line 1656, in device
    return self._setup_devices
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/transformers/utils/generic.py", line 54, in __get__
    cached = self.fget(obj)
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/transformers/training_args.py", line 1646, in _setup_devices
    return self._setup_devices    
torch.cuda.set_device(device)
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/transformers/utils/generic.py", line 54, in __get__
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/cuda/__init__.py", line 350, in set_device
    torch._C._cuda_setDevice(device)
RuntimeError:     CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
cached = self.fget(obj)

  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/transformers/training_args.py", line 1646, in _setup_devices
    torch.cuda.set_device(device)
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/cuda/__init__.py", line 350, in set_device
    torch._C._cuda_setDevice(device)
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20159 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 20160) of binary: /home/namz2/.conda/envs/alpaca/bin/python
Traceback (most recent call last):
  File "/home/namz2/.conda/envs/alpaca/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-04-03_18:35:40
  host      : mint
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 20161)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-04-03_18:35:40
  host      : mint
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 20160)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[2023-04-03 18:36:28,353] [INFO] [comm.py:652:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-04-03 18:36:38,053] [INFO] [partition_parameters.py:415:__exit__] finished initializing model with 6.74B parameters
Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]Loading checkpoint shards:   3%|â–Ž         | 1/33 [00:00<00:14,  2.14it/s]Loading checkpoint shards:   6%|â–Œ         | 2/33 [00:00<00:14,  2.14it/s]Loading checkpoint shards:   9%|â–‰         | 3/33 [00:01<00:13,  2.15it/s]Loading checkpoint shards:  12%|â–ˆâ–        | 4/33 [00:01<00:13,  2.15it/s]Loading checkpoint shards:  15%|â–ˆâ–Œ        | 5/33 [00:02<00:13,  2.12it/s]Loading checkpoint shards:  18%|â–ˆâ–Š        | 6/33 [00:02<00:12,  2.13it/s]Loading checkpoint shards:  21%|â–ˆâ–ˆ        | 7/33 [00:03<00:12,  2.13it/s]Loading checkpoint shards:  24%|â–ˆâ–ˆâ–       | 8/33 [00:03<00:11,  2.13it/s]Loading checkpoint shards:  27%|â–ˆâ–ˆâ–‹       | 9/33 [00:04<00:11,  2.12it/s]Loading checkpoint shards:  30%|â–ˆâ–ˆâ–ˆ       | 10/33 [00:04<00:10,  2.13it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 11/33 [00:05<00:10,  2.12it/s]Loading checkpoint shards:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 12/33 [00:05<00:09,  2.11it/s]Loading checkpoint shards:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 13/33 [00:06<00:09,  2.12it/s]Loading checkpoint shards:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/33 [00:06<00:08,  2.13it/s]Loading checkpoint shards:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 15/33 [00:07<00:08,  2.13it/s]Loading checkpoint shards:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 16/33 [00:07<00:07,  2.13it/s]Loading checkpoint shards:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:07<00:07,  2.14it/s]Loading checkpoint shards:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/33 [00:08<00:07,  2.14it/s]Loading checkpoint shards:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 19/33 [00:08<00:06,  2.13it/s]Loading checkpoint shards:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 20/33 [00:09<00:06,  2.12it/s]Loading checkpoint shards:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 21/33 [00:09<00:05,  2.12it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 22/33 [00:10<00:05,  2.13it/s]Loading checkpoint shards:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:10<00:04,  2.14it/s]Loading checkpoint shards:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:11<00:04,  2.15it/s]Loading checkpoint shards:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:11<00:03,  2.12it/s]Loading checkpoint shards:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 26/33 [00:12<00:03,  2.13it/s]Loading checkpoint shards:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:12<00:02,  2.14it/s]Loading checkpoint shards:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:13<00:02,  2.13it/s]Loading checkpoint shards:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:13<00:01,  2.14it/s]Loading checkpoint shards:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:14<00:01,  2.13it/s]Loading checkpoint shards:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 31/33 [00:14<00:00,  2.14it/s]Loading checkpoint shards:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 32/33 [00:15<00:00,  2.13it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:15<00:00,  1.99it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:15<00:00,  2.12it/s]
Using pad_token, but it is not set yet.
WARNING:root:Loading data...
WARNING:root:Formatting inputs...
WARNING:root:Tokenizing inputs... This may take some time...
Using /home/namz2/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Emitting ninja build file /home/namz2/.cache/torch_extensions/py39_cu117/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3898477554321289 seconds
Parameter Offload: Total persistent parameters: 0 in 0 params
Using /home/namz2/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0004611015319824219 seconds
wandb: Currently logged in as: dlxogn12345 (thlee). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /mnt/data1/namz2/taewhoo/NLP/stanford_alpaca/wandb/run-20230403_183919-3cwopqh1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-cosmos-11
wandb: â­ï¸ View project at https://wandb.ai/thlee/huggingface
wandb: ðŸš€ View run at https://wandb.ai/thlee/huggingface/runs/3cwopqh1
  0%|          | 0/10398 [00:00<?, ?it/s]/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:2547: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.
  warnings.warn(
/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:3015: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.
  warnings.warn(
  0%|          | 1/10398 [00:33<96:21:50, 33.37s/it]                                                    {'loss': 1.7115, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 1/10398 [00:33<96:21:50, 33.37s/it]  0%|          | 2/10398 [01:06<95:31:28, 33.08s/it]                                                    {'loss': 1.8135, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 2/10398 [01:06<95:31:28, 33.08s/it]  0%|          | 3/10398 [01:39<95:13:50, 32.98s/it]                                                    {'loss': 1.3817, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 3/10398 [01:39<95:13:50, 32.98s/it]  0%|          | 4/10398 [02:11<94:55:09, 32.88s/it]                                                    {'loss': 1.5023, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 4/10398 [02:11<94:55:09, 32.88s/it]  0%|          | 5/10398 [02:44<94:47:57, 32.84s/it]                                                    {'loss': 1.548, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 5/10398 [02:44<94:47:57, 32.84s/it]  0%|          | 6/10398 [03:17<94:47:30, 32.84s/it]                                                    {'loss': 1.5013, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 6/10398 [03:17<94:47:30, 32.84s/it]  0%|          | 7/10398 [03:50<94:50:31, 32.86s/it]                                                    {'loss': 1.5252, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 7/10398 [03:50<94:50:31, 32.86s/it]  0%|          | 8/10398 [04:23<94:51:19, 32.87s/it]                                                    {'loss': 1.7154, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 8/10398 [04:23<94:51:19, 32.87s/it]  0%|          | 9/10398 [04:56<94:59:42, 32.92s/it]                                                    {'loss': 1.6252, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 9/10398 [04:56<94:59:42, 32.92s/it]  0%|          | 10/10398 [05:29<94:59:13, 32.92s/it]                                                     {'loss': 1.665, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 10/10398 [05:29<94:59:13, 32.92s/it]  0%|          | 11/10398 [06:02<95:01:43, 32.94s/it]                                                     {'loss': 1.5148, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 11/10398 [06:02<95:01:43, 32.94s/it]  0%|          | 12/10398 [06:35<95:00:18, 32.93s/it]                                                     {'loss': 1.759, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 12/10398 [06:35<95:00:18, 32.93s/it]  0%|          | 13/10398 [07:07<94:56:12, 32.91s/it]                                                     {'loss': 1.5055, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 13/10398 [07:07<94:56:12, 32.91s/it]  0%|          | 14/10398 [07:40<94:49:48, 32.88s/it]                                                     {'loss': 1.5914, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 14/10398 [07:40<94:49:48, 32.88s/it]  0%|          | 15/10398 [08:13<94:43:08, 32.84s/it]                                                     {'loss': 1.7701, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 15/10398 [08:13<94:43:08, 32.84s/it]  0%|          | 16/10398 [08:46<94:47:31, 32.87s/it]                                                     {'loss': 1.5252, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 16/10398 [08:46<94:47:31, 32.87s/it]  0%|          | 17/10398 [09:19<95:00:32, 32.95s/it]                                                     {'loss': 1.5951, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 17/10398 [09:19<95:00:32, 32.95s/it]  0%|          | 18/10398 [10:07<108:14:52, 37.54s/it]                                                      {'loss': 1.2956, 'learning_rate': 6.41025641025641e-08, 'epoch': 0.01}
  0%|          | 18/10398 [10:07<108:14:52, 37.54s/it]  0%|          | 19/10398 [10:40<103:59:24, 36.07s/it]                                                      {'loss': 1.6715, 'learning_rate': 6.41025641025641e-08, 'epoch': 0.01}
  0%|          | 19/10398 [10:40<103:59:24, 36.07s/it]  0%|          | 20/10398 [11:13<101:04:39, 35.06s/it]                                                      {'loss': 1.9979, 'learning_rate': 6.41025641025641e-08, 'epoch': 0.01}
  0%|          | 20/10398 [11:13<101:04:39, 35.06s/it]  0%|          | 21/10398 [12:00<111:36:09, 38.72s/it]                                                      {'loss': 1.7088, 'learning_rate': 1.282051282051282e-07, 'epoch': 0.01}
  0%|          | 21/10398 [12:00<111:36:09, 38.72s/it]  0%|          | 22/10398 [12:47<119:07:09, 41.33s/it]                                                      {'loss': 1.2644, 'learning_rate': 1.9230769230769234e-07, 'epoch': 0.01}
  0%|          | 22/10398 [12:47<119:07:09, 41.33s/it]  0%|          | 23/10398 [13:35<124:17:48, 43.13s/it]                                                      {'loss': 1.6459, 'learning_rate': 2.564102564102564e-07, 'epoch': 0.01}
  0%|          | 23/10398 [13:35<124:17:48, 43.13s/it]  0%|          | 24/10398 [14:22<127:57:07, 44.40s/it]                                                      {'loss': 1.7018, 'learning_rate': 3.205128205128205e-07, 'epoch': 0.01}
  0%|          | 24/10398 [14:22<127:57:07, 44.40s/it]  0%|          | 25/10398 [15:09<130:27:39, 45.28s/it]                                                      {'loss': 1.5854, 'learning_rate': 3.846153846153847e-07, 'epoch': 0.01}
  0%|          | 25/10398 [15:09<130:27:39, 45.28s/it]  0%|          | 26/10398 [15:56<132:04:14, 45.84s/it]                                                      {'loss': 1.5908, 'learning_rate': 4.4871794871794876e-07, 'epoch': 0.01}
  0%|          | 26/10398 [15:56<132:04:14, 45.84s/it]  0%|          | 27/10398 [16:44<133:24:51, 46.31s/it]                                                      {'loss': 1.6701, 'learning_rate': 5.128205128205128e-07, 'epoch': 0.01}
  0%|          | 27/10398 [16:44<133:24:51, 46.31s/it]  0%|          | 28/10398 [17:31<134:11:17, 46.58s/it]                                                      {'loss': 1.4154, 'learning_rate': 5.76923076923077e-07, 'epoch': 0.01}
  0%|          | 28/10398 [17:31<134:11:17, 46.58s/it]  0%|          | 29/10398 [18:19<134:56:48, 46.85s/it]                                                      {'loss': 1.6324, 'learning_rate': 6.41025641025641e-07, 'epoch': 0.01}
  0%|          | 29/10398 [18:19<134:56:48, 46.85s/it]  0%|          | 30/10398 [19:06<135:25:51, 47.02s/it]                                                      {'loss': 1.6013, 'learning_rate': 7.051282051282052e-07, 'epoch': 0.01}
  0%|          | 30/10398 [19:06<135:25:51, 47.02s/it]  0%|          | 31/10398 [19:54<136:03:20, 47.25s/it]                                                      {'loss': 1.4865, 'learning_rate': 7.692307692307694e-07, 'epoch': 0.01}
  0%|          | 31/10398 [19:54<136:03:20, 47.25s/it]  0%|          | 32/10398 [20:41<136:05:52, 47.27s/it]                                                      {'loss': 1.4094, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.01}
  0%|          | 32/10398 [20:41<136:05:52, 47.27s/it]  0%|          | 33/10398 [21:28<135:58:18, 47.23s/it]                                                      {'loss': 1.4859, 'learning_rate': 8.974358974358975e-07, 'epoch': 0.01}
  0%|          | 33/10398 [21:28<135:58:18, 47.23s/it]  0%|          | 34/10398 [22:16<136:04:33, 47.27s/it]                                                      {'loss': 1.3723, 'learning_rate': 9.615384615384617e-07, 'epoch': 0.01}
  0%|          | 34/10398 [22:16<136:04:33, 47.27s/it]  0%|          | 35/10398 [23:03<136:08:37, 47.29s/it]                                                      {'loss': 1.3947, 'learning_rate': 1.0256410256410257e-06, 'epoch': 0.01}
  0%|          | 35/10398 [23:03<136:08:37, 47.29s/it]  0%|          | 36/10398 [23:50<136:00:40, 47.25s/it]                                                      {'loss': 1.2211, 'learning_rate': 1.0897435897435899e-06, 'epoch': 0.01}
  0%|          | 36/10398 [23:50<136:00:40, 47.25s/it]  0%|          | 37/10398 [24:38<136:13:15, 47.33s/it]                                                      {'loss': 1.0664, 'learning_rate': 1.153846153846154e-06, 'epoch': 0.01}
  0%|          | 37/10398 [24:38<136:13:15, 47.33s/it]  0%|          | 38/10398 [25:25<136:07:21, 47.30s/it]                                                      {'loss': 1.1897, 'learning_rate': 1.217948717948718e-06, 'epoch': 0.01}
  0%|          | 38/10398 [25:25<136:07:21, 47.30s/it]  0%|          | 39/10398 [26:13<136:29:54, 47.44s/it]                                                      {'loss': 1.2156, 'learning_rate': 1.282051282051282e-06, 'epoch': 0.01}
  0%|          | 39/10398 [26:13<136:29:54, 47.44s/it]  0%|          | 40/10398 [27:00<136:18:19, 47.37s/it]                                                      {'loss': 1.3155, 'learning_rate': 1.3461538461538462e-06, 'epoch': 0.01}
  0%|          | 40/10398 [27:00<136:18:19, 47.37s/it]  0%|          | 41/10398 [27:47<136:23:30, 47.41s/it]                                                      {'loss': 1.2677, 'learning_rate': 1.4102564102564104e-06, 'epoch': 0.01}
  0%|          | 41/10398 [27:47<136:23:30, 47.41s/it]  0%|          | 42/10398 [28:35<136:19:12, 47.39s/it]                                                      {'loss': 1.416, 'learning_rate': 1.4743589743589745e-06, 'epoch': 0.01}
  0%|          | 42/10398 [28:35<136:19:12, 47.39s/it]  0%|          | 43/10398 [29:22<136:18:01, 47.39s/it]                                                      {'loss': 1.5299, 'learning_rate': 1.5384615384615387e-06, 'epoch': 0.01}
  0%|          | 43/10398 [29:22<136:18:01, 47.39s/it]  0%|          | 44/10398 [30:09<136:13:35, 47.36s/it]                                                      {'loss': 1.1706, 'learning_rate': 1.602564102564103e-06, 'epoch': 0.01}
  0%|          | 44/10398 [30:09<136:13:35, 47.36s/it]  0%|          | 45/10398 [30:57<136:21:57, 47.42s/it]                                                      {'loss': 1.3036, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.01}
  0%|          | 45/10398 [30:57<136:21:57, 47.42s/it]  0%|          | 46/10398 [31:44<136:12:13, 47.37s/it]                                                      {'loss': 1.0763, 'learning_rate': 1.7307692307692308e-06, 'epoch': 0.01}
  0%|          | 46/10398 [31:44<136:12:13, 47.37s/it]  0%|          | 47/10398 [32:31<136:06:53, 47.34s/it]                                                      {'loss': 1.3865, 'learning_rate': 1.794871794871795e-06, 'epoch': 0.01}
  0%|          | 47/10398 [32:31<136:06:53, 47.34s/it]  0%|          | 48/10398 [33:19<136:00:13, 47.31s/it]                                                      {'loss': 1.193, 'learning_rate': 1.8589743589743592e-06, 'epoch': 0.01}
  0%|          | 48/10398 [33:19<136:00:13, 47.31s/it]  0%|          | 49/10398 [34:06<135:53:23, 47.27s/it]                                                      {'loss': 1.457, 'learning_rate': 1.9230769230769234e-06, 'epoch': 0.01}
  0%|          | 49/10398 [34:06<135:53:23, 47.27s/it]  0%|          | 50/10398 [34:53<136:00:39, 47.32s/it]                                                      {'loss': 0.9785, 'learning_rate': 1.987179487179487e-06, 'epoch': 0.01}
  0%|          | 50/10398 [34:53<136:00:39, 47.32s/it]  0%|          | 51/10398 [35:41<136:16:50, 47.42s/it]                                                      {'loss': 1.0536, 'learning_rate': 2.0512820512820513e-06, 'epoch': 0.01}
  0%|          | 51/10398 [35:41<136:16:50, 47.42s/it]  1%|          | 52/10398 [36:29<136:40:47, 47.56s/it]                                                      {'loss': 0.9338, 'learning_rate': 2.1153846153846155e-06, 'epoch': 0.01}
  1%|          | 52/10398 [36:29<136:40:47, 47.56s/it]  1%|          | 53/10398 [37:17<137:02:54, 47.69s/it]                                                      {'loss': 1.3133, 'learning_rate': 2.1794871794871797e-06, 'epoch': 0.02}
  1%|          | 53/10398 [37:17<137:02:54, 47.69s/it]  1%|          | 54/10398 [38:05<137:29:17, 47.85s/it]                                                      {'loss': 1.2165, 'learning_rate': 2.243589743589744e-06, 'epoch': 0.02}
  1%|          | 54/10398 [38:05<137:29:17, 47.85s/it]  1%|          | 55/10398 [38:52<137:01:38, 47.69s/it]                                                      {'loss': 1.3604, 'learning_rate': 2.307692307692308e-06, 'epoch': 0.02}
  1%|          | 55/10398 [38:52<137:01:38, 47.69s/it]  1%|          | 56/10398 [39:40<136:34:19, 47.54s/it]                                                      {'loss': 1.3554, 'learning_rate': 2.371794871794872e-06, 'epoch': 0.02}
  1%|          | 56/10398 [39:40<136:34:19, 47.54s/it]  1%|          | 57/10398 [40:27<136:10:34, 47.41s/it]                                                      {'loss': 1.2529, 'learning_rate': 2.435897435897436e-06, 'epoch': 0.02}
  1%|          | 57/10398 [40:27<136:10:34, 47.41s/it]  1%|          | 58/10398 [41:14<136:08:10, 47.40s/it]                                                      {'loss': 1.1603, 'learning_rate': 2.5e-06, 'epoch': 0.02}
  1%|          | 58/10398 [41:14<136:08:10, 47.40s/it]  1%|          | 59/10398 [42:01<135:58:57, 47.35s/it]                                                      {'loss': 1.3926, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.02}
  1%|          | 59/10398 [42:01<135:58:57, 47.35s/it]  1%|          | 60/10398 [42:49<136:01:44, 47.37s/it]                                                      {'loss': 1.2293, 'learning_rate': 2.6282051282051286e-06, 'epoch': 0.02}
  1%|          | 60/10398 [42:49<136:01:44, 47.37s/it]  1%|          | 61/10398 [43:36<135:59:59, 47.36s/it]                                                      {'loss': 1.002, 'learning_rate': 2.6923076923076923e-06, 'epoch': 0.02}
  1%|          | 61/10398 [43:36<135:59:59, 47.36s/it]  1%|          | 62/10398 [44:23<136:00:15, 47.37s/it]                                                      {'loss': 1.1161, 'learning_rate': 2.756410256410257e-06, 'epoch': 0.02}
  1%|          | 62/10398 [44:23<136:00:15, 47.37s/it]  1%|          | 63/10398 [45:11<136:02:29, 47.39s/it]                                                      {'loss': 1.2066, 'learning_rate': 2.8205128205128207e-06, 'epoch': 0.02}
  1%|          | 63/10398 [45:11<136:02:29, 47.39s/it]  1%|          | 64/10398 [45:58<135:54:25, 47.35s/it]                                                      {'loss': 1.0383, 'learning_rate': 2.8846153846153845e-06, 'epoch': 0.02}
  1%|          | 64/10398 [45:58<135:54:25, 47.35s/it]  1%|          | 65/10398 [46:45<135:57:18, 47.37s/it]                                                      {'loss': 1.1998, 'learning_rate': 2.948717948717949e-06, 'epoch': 0.02}
  1%|          | 65/10398 [46:45<135:57:18, 47.37s/it]  1%|          | 66/10398 [47:33<135:42:37, 47.29s/it]                                                      {'loss': 1.2692, 'learning_rate': 3.012820512820513e-06, 'epoch': 0.02}
  1%|          | 66/10398 [47:33<135:42:37, 47.29s/it]  1%|          | 67/10398 [48:20<135:37:57, 47.26s/it]                                                      {'loss': 1.1677, 'learning_rate': 3.0769230769230774e-06, 'epoch': 0.02}
  1%|          | 67/10398 [48:20<135:37:57, 47.26s/it]  1%|          | 68/10398 [49:07<135:35:50, 47.26s/it]                                                      {'loss': 1.0353, 'learning_rate': 3.141025641025641e-06, 'epoch': 0.02}
  1%|          | 68/10398 [49:07<135:35:50, 47.26s/it]  1%|          | 69/10398 [49:54<135:37:12, 47.27s/it]                                                      {'loss': 1.1216, 'learning_rate': 3.205128205128206e-06, 'epoch': 0.02}
  1%|          | 69/10398 [49:54<135:37:12, 47.27s/it]  1%|          | 70/10398 [50:42<135:55:30, 47.38s/it]                                                      {'loss': 1.1361, 'learning_rate': 3.2692307692307696e-06, 'epoch': 0.02}
  1%|          | 70/10398 [50:42<135:55:30, 47.38s/it]  1%|          | 71/10398 [51:29<135:53:09, 47.37s/it]                                                      {'loss': 1.0319, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.02}
  1%|          | 71/10398 [51:29<135:53:09, 47.37s/it]  1%|          | 72/10398 [52:17<136:24:02, 47.55s/it]                                                      {'loss': 1.2366, 'learning_rate': 3.397435897435898e-06, 'epoch': 0.02}
  1%|          | 72/10398 [52:17<136:24:02, 47.55s/it]  1%|          | 73/10398 [53:05<136:09:14, 47.47s/it]                                                      {'loss': 1.0947, 'learning_rate': 3.4615384615384617e-06, 'epoch': 0.02}
  1%|          | 73/10398 [53:05<136:09:14, 47.47s/it]  1%|          | 74/10398 [53:52<135:58:59, 47.42s/it]                                                      {'loss': 1.08, 'learning_rate': 3.5256410256410263e-06, 'epoch': 0.02}
  1%|          | 74/10398 [53:52<135:58:59, 47.42s/it]  1%|          | 75/10398 [54:39<135:57:36, 47.41s/it]                                                      {'loss': 1.1617, 'learning_rate': 3.58974358974359e-06, 'epoch': 0.02}
  1%|          | 75/10398 [54:39<135:57:36, 47.41s/it]  1%|          | 76/10398 [55:27<135:55:21, 47.41s/it]                                                      {'loss': 1.1027, 'learning_rate': 3.653846153846154e-06, 'epoch': 0.02}
  1%|          | 76/10398 [55:27<135:55:21, 47.41s/it]  1%|          | 77/10398 [56:15<136:19:33, 47.55s/it]                                                      {'loss': 1.2654, 'learning_rate': 3.7179487179487184e-06, 'epoch': 0.02}
  1%|          | 77/10398 [56:15<136:19:33, 47.55s/it]  1%|          | 78/10398 [57:02<135:59:42, 47.44s/it]                                                      {'loss': 1.0639, 'learning_rate': 3.782051282051282e-06, 'epoch': 0.02}
  1%|          | 78/10398 [57:02<135:59:42, 47.44s/it]  1%|          | 79/10398 [57:49<135:50:13, 47.39s/it]                                                      {'loss': 1.1881, 'learning_rate': 3.846153846153847e-06, 'epoch': 0.02}
  1%|          | 79/10398 [57:49<135:50:13, 47.39s/it]  1%|          | 80/10398 [58:36<135:50:19, 47.39s/it]                                                      {'loss': 1.2096, 'learning_rate': 3.910256410256411e-06, 'epoch': 0.02}
  1%|          | 80/10398 [58:36<135:50:19, 47.39s/it]  1%|          | 81/10398 [59:24<135:41:16, 47.35s/it]                                                      {'loss': 1.0657, 'learning_rate': 3.974358974358974e-06, 'epoch': 0.02}
  1%|          | 81/10398 [59:24<135:41:16, 47.35s/it]  1%|          | 82/10398 [1:00:11<135:40:36, 47.35s/it]                                                        {'loss': 1.0192, 'learning_rate': 4.0384615384615385e-06, 'epoch': 0.02}
  1%|          | 82/10398 [1:00:11<135:40:36, 47.35s/it]  1%|          | 83/10398 [1:00:59<136:05:51, 47.50s/it]                                                        {'loss': 1.1647, 'learning_rate': 4.102564102564103e-06, 'epoch': 0.02}
  1%|          | 83/10398 [1:00:59<136:05:51, 47.50s/it]  1%|          | 84/10398 [1:01:46<135:57:59, 47.46s/it]                                                        {'loss': 1.1777, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.02}
  1%|          | 84/10398 [1:01:46<135:57:59, 47.46s/it]  1%|          | 85/10398 [1:02:34<135:59:16, 47.47s/it]                                                        {'loss': 0.8305, 'learning_rate': 4.230769230769231e-06, 'epoch': 0.02}
  1%|          | 85/10398 [1:02:34<135:59:16, 47.47s/it]  1%|          | 86/10398 [1:03:21<136:06:23, 47.52s/it]                                                        {'loss': 1.1561, 'learning_rate': 4.294871794871795e-06, 'epoch': 0.02}
  1%|          | 86/10398 [1:03:21<136:06:23, 47.52s/it]  1%|          | 87/10398 [1:04:09<136:02:16, 47.50s/it]                                                        {'loss': 1.1533, 'learning_rate': 4.358974358974359e-06, 'epoch': 0.03}
  1%|          | 87/10398 [1:04:09<136:02:16, 47.50s/it]  1%|          | 88/10398 [1:04:56<135:58:25, 47.48s/it]                                                        {'loss': 1.2245, 'learning_rate': 4.423076923076924e-06, 'epoch': 0.03}
  1%|          | 88/10398 [1:04:56<135:58:25, 47.48s/it]  1%|          | 89/10398 [1:05:44<136:08:22, 47.54s/it]                                                        {'loss': 1.0958, 'learning_rate': 4.487179487179488e-06, 'epoch': 0.03}
  1%|          | 89/10398 [1:05:44<136:08:22, 47.54s/it]  1%|          | 90/10398 [1:06:31<135:53:56, 47.46s/it]                                                        {'loss': 1.0155, 'learning_rate': 4.551282051282052e-06, 'epoch': 0.03}
  1%|          | 90/10398 [1:06:31<135:53:56, 47.46s/it]  1%|          | 91/10398 [1:07:19<135:47:03, 47.43s/it]                                                        {'loss': 1.16, 'learning_rate': 4.615384615384616e-06, 'epoch': 0.03}
  1%|          | 91/10398 [1:07:19<135:47:03, 47.43s/it]  1%|          | 92/10398 [1:08:06<135:50:02, 47.45s/it]                                                        {'loss': 1.026, 'learning_rate': 4.6794871794871795e-06, 'epoch': 0.03}
  1%|          | 92/10398 [1:08:06<135:50:02, 47.45s/it]  1%|          | 93/10398 [1:08:53<135:46:59, 47.44s/it]                                                        {'loss': 1.3137, 'learning_rate': 4.743589743589744e-06, 'epoch': 0.03}
  1%|          | 93/10398 [1:08:53<135:46:59, 47.44s/it]  1%|          | 94/10398 [1:09:41<135:44:00, 47.42s/it]                                                        {'loss': 1.0151, 'learning_rate': 4.807692307692308e-06, 'epoch': 0.03}
  1%|          | 94/10398 [1:09:41<135:44:00, 47.42s/it]  1%|          | 95/10398 [1:10:28<135:54:02, 47.49s/it]                                                        {'loss': 0.9405, 'learning_rate': 4.871794871794872e-06, 'epoch': 0.03}
  1%|          | 95/10398 [1:10:28<135:54:02, 47.49s/it]  1%|          | 96/10398 [1:11:16<135:55:26, 47.50s/it]                                                        {'loss': 1.1009, 'learning_rate': 4.935897435897436e-06, 'epoch': 0.03}
  1%|          | 96/10398 [1:11:16<135:55:26, 47.50s/it]  1%|          | 97/10398 [1:12:03<135:40:51, 47.42s/it]                                                        {'loss': 1.0392, 'learning_rate': 5e-06, 'epoch': 0.03}
  1%|          | 97/10398 [1:12:03<135:40:51, 47.42s/it]  1%|          | 98/10398 [1:12:51<135:56:06, 47.51s/it]                                                        {'loss': 1.1419, 'learning_rate': 5.064102564102565e-06, 'epoch': 0.03}
  1%|          | 98/10398 [1:12:51<135:56:06, 47.51s/it]  1%|          | 99/10398 [1:13:38<135:45:16, 47.45s/it]                                                        {'loss': 1.2828, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.03}
  1%|          | 99/10398 [1:13:38<135:45:16, 47.45s/it]  1%|          | 100/10398 [1:14:25<135:25:08, 47.34s/it]                                                         {'loss': 1.1874, 'learning_rate': 5.192307692307693e-06, 'epoch': 0.03}
  1%|          | 100/10398 [1:14:25<135:25:08, 47.34s/it]  1%|          | 101/10398 [1:15:13<135:22:25, 47.33s/it]                                                         {'loss': 0.9038, 'learning_rate': 5.256410256410257e-06, 'epoch': 0.03}
  1%|          | 101/10398 [1:15:13<135:22:25, 47.33s/it]  1%|          | 102/10398 [1:16:00<135:40:29, 47.44s/it]                                                         {'loss': 1.3088, 'learning_rate': 5.320512820512821e-06, 'epoch': 0.03}
  1%|          | 102/10398 [1:16:00<135:40:29, 47.44s/it]  1%|          | 103/10398 [1:16:48<135:33:03, 47.40s/it]                                                         {'loss': 0.8989, 'learning_rate': 5.384615384615385e-06, 'epoch': 0.03}
  1%|          | 103/10398 [1:16:48<135:33:03, 47.40s/it]  1%|          | 104/10398 [1:17:35<135:23:40, 47.35s/it]                                                         {'loss': 1.1426, 'learning_rate': 5.448717948717949e-06, 'epoch': 0.03}
  1%|          | 104/10398 [1:17:35<135:23:40, 47.35s/it]  1%|          | 105/10398 [1:18:22<135:22:48, 47.35s/it]                                                         {'loss': 1.1833, 'learning_rate': 5.512820512820514e-06, 'epoch': 0.03}
  1%|          | 105/10398 [1:18:22<135:22:48, 47.35s/it]  1%|          | 106/10398 [1:19:10<135:19:29, 47.33s/it]                                                         {'loss': 1.161, 'learning_rate': 5.576923076923077e-06, 'epoch': 0.03}
  1%|          | 106/10398 [1:19:10<135:19:29, 47.33s/it]  1%|          | 107/10398 [1:19:57<135:20:03, 47.34s/it]                                                         {'loss': 1.135, 'learning_rate': 5.641025641025641e-06, 'epoch': 0.03}
  1%|          | 107/10398 [1:19:57<135:20:03, 47.34s/it]  1%|          | 108/10398 [1:20:44<135:11:11, 47.30s/it]                                                         {'loss': 1.3867, 'learning_rate': 5.705128205128206e-06, 'epoch': 0.03}
  1%|          | 108/10398 [1:20:44<135:11:11, 47.30s/it]  1%|          | 109/10398 [1:21:32<135:19:37, 47.35s/it]                                                         {'loss': 0.9594, 'learning_rate': 5.769230769230769e-06, 'epoch': 0.03}
  1%|          | 109/10398 [1:21:32<135:19:37, 47.35s/it]  1%|          | 110/10398 [1:22:19<135:19:12, 47.35s/it]                                                         {'loss': 1.1767, 'learning_rate': 5.833333333333334e-06, 'epoch': 0.03}
  1%|          | 110/10398 [1:22:19<135:19:12, 47.35s/it]  1%|          | 111/10398 [1:23:06<135:21:35, 47.37s/it]                                                         {'loss': 0.7847, 'learning_rate': 5.897435897435898e-06, 'epoch': 0.03}
  1%|          | 111/10398 [1:23:06<135:21:35, 47.37s/it]  1%|          | 112/10398 [1:23:54<135:14:22, 47.33s/it]                                                         {'loss': 1.1604, 'learning_rate': 5.961538461538462e-06, 'epoch': 0.03}
  1%|          | 112/10398 [1:23:54<135:14:22, 47.33s/it]  1%|          | 113/10398 [1:24:41<135:21:31, 47.38s/it]                                                         {'loss': 0.8617, 'learning_rate': 6.025641025641026e-06, 'epoch': 0.03}
  1%|          | 113/10398 [1:24:41<135:21:31, 47.38s/it]  1%|          | 114/10398 [1:25:28<135:13:54, 47.34s/it]                                                         {'loss': 1.1515, 'learning_rate': 6.08974358974359e-06, 'epoch': 0.03}
  1%|          | 114/10398 [1:25:28<135:13:54, 47.34s/it]  1%|          | 115/10398 [1:26:16<135:26:33, 47.42s/it]                                                         {'loss': 1.0733, 'learning_rate': 6.153846153846155e-06, 'epoch': 0.03}
  1%|          | 115/10398 [1:26:16<135:26:33, 47.42s/it]  1%|          | 116/10398 [1:27:03<135:29:13, 47.44s/it]                                                         {'loss': 1.1771, 'learning_rate': 6.217948717948718e-06, 'epoch': 0.03}
  1%|          | 116/10398 [1:27:03<135:29:13, 47.44s/it]  1%|          | 117/10398 [1:27:51<135:22:45, 47.40s/it]                                                         {'loss': 1.2215, 'learning_rate': 6.282051282051282e-06, 'epoch': 0.03}
  1%|          | 117/10398 [1:27:51<135:22:45, 47.40s/it]  1%|          | 118/10398 [1:28:38<135:23:10, 47.41s/it]                                                         {'loss': 0.9328, 'learning_rate': 6.3461538461538466e-06, 'epoch': 0.03}
  1%|          | 118/10398 [1:28:38<135:23:10, 47.41s/it]  1%|          | 119/10398 [1:29:26<135:35:18, 47.49s/it]                                                         {'loss': 0.975, 'learning_rate': 6.410256410256412e-06, 'epoch': 0.03}
  1%|          | 119/10398 [1:29:26<135:35:18, 47.49s/it]  1%|          | 120/10398 [1:30:14<135:51:40, 47.59s/it]                                                         {'loss': 1.2372, 'learning_rate': 6.474358974358975e-06, 'epoch': 0.03}
  1%|          | 120/10398 [1:30:14<135:51:40, 47.59s/it]  1%|          | 121/10398 [1:31:01<135:41:07, 47.53s/it]                                                         {'loss': 1.1153, 'learning_rate': 6.538461538461539e-06, 'epoch': 0.03}
  1%|          | 121/10398 [1:31:01<135:41:07, 47.53s/it]  1%|          | 122/10398 [1:31:49<135:55:29, 47.62s/it]                                                         {'loss': 0.8431, 'learning_rate': 6.602564102564103e-06, 'epoch': 0.04}
  1%|          | 122/10398 [1:31:49<135:55:29, 47.62s/it]  1%|          | 123/10398 [1:32:36<135:51:17, 47.60s/it]                                                         {'loss': 1.1939, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.04}
  1%|          | 123/10398 [1:32:36<135:51:17, 47.60s/it]  1%|          | 124/10398 [1:33:24<135:51:56, 47.61s/it]                                                         {'loss': 1.1881, 'learning_rate': 6.730769230769232e-06, 'epoch': 0.04}
  1%|          | 124/10398 [1:33:24<135:51:56, 47.61s/it]  1%|          | 125/10398 [1:34:11<135:28:59, 47.48s/it]                                                         {'loss': 0.9883, 'learning_rate': 6.794871794871796e-06, 'epoch': 0.04}
  1%|          | 125/10398 [1:34:11<135:28:59, 47.48s/it]  1%|          | 126/10398 [1:34:58<135:17:42, 47.42s/it]                                                         {'loss': 1.3715, 'learning_rate': 6.858974358974359e-06, 'epoch': 0.04}
  1%|          | 126/10398 [1:34:58<135:17:42, 47.42s/it]  1%|          | 127/10398 [1:35:46<135:16:06, 47.41s/it]                                                         {'loss': 1.1378, 'learning_rate': 6.923076923076923e-06, 'epoch': 0.04}
  1%|          | 127/10398 [1:35:46<135:16:06, 47.41s/it]  1%|          | 128/10398 [1:36:34<135:39:58, 47.56s/it]                                                         {'loss': 1.002, 'learning_rate': 6.9871794871794876e-06, 'epoch': 0.04}
  1%|          | 128/10398 [1:36:34<135:39:58, 47.56s/it]  1%|          | 129/10398 [1:37:21<135:27:08, 47.49s/it]                                                         {'loss': 1.3283, 'learning_rate': 7.051282051282053e-06, 'epoch': 0.04}
  1%|          | 129/10398 [1:37:21<135:27:08, 47.49s/it]  1%|â–         | 130/10398 [1:38:08<135:20:04, 47.45s/it]                                                         {'loss': 1.1613, 'learning_rate': 7.115384615384616e-06, 'epoch': 0.04}
  1%|â–         | 130/10398 [1:38:08<135:20:04, 47.45s/it]  1%|â–         | 131/10398 [1:38:56<135:09:44, 47.39s/it]                                                         {'loss': 1.0554, 'learning_rate': 7.17948717948718e-06, 'epoch': 0.04}
  1%|â–         | 131/10398 [1:38:56<135:09:44, 47.39s/it]  1%|â–         | 132/10398 [1:39:43<135:07:24, 47.38s/it]                                                         {'loss': 1.0525, 'learning_rate': 7.243589743589744e-06, 'epoch': 0.04}
  1%|â–         | 132/10398 [1:39:43<135:07:24, 47.38s/it]  1%|â–         | 133/10398 [1:40:30<135:04:52, 47.37s/it]                                                         {'loss': 1.2969, 'learning_rate': 7.307692307692308e-06, 'epoch': 0.04}
  1%|â–         | 133/10398 [1:40:30<135:04:52, 47.37s/it]  1%|â–         | 134/10398 [1:41:18<135:09:33, 47.41s/it]                                                         {'loss': 1.0818, 'learning_rate': 7.371794871794873e-06, 'epoch': 0.04}
  1%|â–         | 134/10398 [1:41:18<135:09:33, 47.41s/it]  1%|â–         | 135/10398 [1:42:05<135:17:29, 47.46s/it]                                                         {'loss': 1.0947, 'learning_rate': 7.435897435897437e-06, 'epoch': 0.04}
  1%|â–         | 135/10398 [1:42:05<135:17:29, 47.46s/it]  1%|â–         | 136/10398 [1:42:53<135:30:38, 47.54s/it]                                                         {'loss': 1.0437, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.04}
  1%|â–         | 136/10398 [1:42:53<135:30:38, 47.54s/it]  1%|â–         | 137/10398 [1:43:41<135:38:46, 47.59s/it]                                                         {'loss': 1.0569, 'learning_rate': 7.564102564102564e-06, 'epoch': 0.04}
  1%|â–         | 137/10398 [1:43:41<135:38:46, 47.59s/it]  1%|â–         | 138/10398 [1:44:28<135:17:22, 47.47s/it]                                                         {'loss': 1.0935, 'learning_rate': 7.6282051282051286e-06, 'epoch': 0.04}
  1%|â–         | 138/10398 [1:44:28<135:17:22, 47.47s/it]  1%|â–         | 139/10398 [1:45:15<135:00:49, 47.38s/it]                                                         {'loss': 0.9937, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.04}
  1%|â–         | 139/10398 [1:45:15<135:00:49, 47.38s/it]  1%|â–         | 140/10398 [1:46:03<135:05:02, 47.41s/it]                                                         {'loss': 1.0434, 'learning_rate': 7.756410256410258e-06, 'epoch': 0.04}
  1%|â–         | 140/10398 [1:46:03<135:05:02, 47.41s/it]  1%|â–         | 141/10398 [1:46:50<135:12:18, 47.45s/it]                                                         {'loss': 1.2366, 'learning_rate': 7.820512820512822e-06, 'epoch': 0.04}
  1%|â–         | 141/10398 [1:46:50<135:12:18, 47.45s/it]  1%|â–         | 142/10398 [1:47:38<135:16:42, 47.48s/it]                                                         {'loss': 1.1823, 'learning_rate': 7.884615384615384e-06, 'epoch': 0.04}
  1%|â–         | 142/10398 [1:47:38<135:16:42, 47.48s/it]  1%|â–         | 143/10398 [1:48:25<135:16:47, 47.49s/it]                                                         {'loss': 1.0814, 'learning_rate': 7.948717948717949e-06, 'epoch': 0.04}
  1%|â–         | 143/10398 [1:48:25<135:16:47, 47.49s/it]  1%|â–         | 144/10398 [1:49:13<135:22:33, 47.53s/it]                                                         {'loss': 1.1162, 'learning_rate': 8.012820512820515e-06, 'epoch': 0.04}
  1%|â–         | 144/10398 [1:49:13<135:22:33, 47.53s/it]  1%|â–         | 145/10398 [1:50:00<135:08:21, 47.45s/it]                                                         {'loss': 1.2576, 'learning_rate': 8.076923076923077e-06, 'epoch': 0.04}
  1%|â–         | 145/10398 [1:50:00<135:08:21, 47.45s/it]  1%|â–         | 146/10398 [1:50:48<135:00:07, 47.41s/it]                                                         {'loss': 1.2068, 'learning_rate': 8.141025641025641e-06, 'epoch': 0.04}
  1%|â–         | 146/10398 [1:50:48<135:00:07, 47.41s/it]  1%|â–         | 147/10398 [1:51:35<135:06:55, 47.45s/it]                                                         {'loss': 1.2945, 'learning_rate': 8.205128205128205e-06, 'epoch': 0.04}
  1%|â–         | 147/10398 [1:51:35<135:06:55, 47.45s/it]  1%|â–         | 148/10398 [1:52:23<135:14:42, 47.50s/it]                                                         {'loss': 1.0346, 'learning_rate': 8.26923076923077e-06, 'epoch': 0.04}
  1%|â–         | 148/10398 [1:52:23<135:14:42, 47.50s/it]  1%|â–         | 149/10398 [1:53:10<135:19:11, 47.53s/it]                                                         {'loss': 1.3656, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.04}
  1%|â–         | 149/10398 [1:53:10<135:19:11, 47.53s/it]  1%|â–         | 150/10398 [1:53:58<135:39:51, 47.66s/it]                                                         {'loss': 1.1939, 'learning_rate': 8.397435897435898e-06, 'epoch': 0.04}
  1%|â–         | 150/10398 [1:53:58<135:39:51, 47.66s/it]  1%|â–         | 151/10398 [1:54:46<135:38:52, 47.66s/it]                                                         {'loss': 1.1086, 'learning_rate': 8.461538461538462e-06, 'epoch': 0.04}
  1%|â–         | 151/10398 [1:54:46<135:38:52, 47.66s/it]  1%|â–         | 152/10398 [1:55:34<135:37:07, 47.65s/it]                                                         {'loss': 1.0594, 'learning_rate': 8.525641025641026e-06, 'epoch': 0.04}
  1%|â–         | 152/10398 [1:55:34<135:37:07, 47.65s/it]  1%|â–         | 153/10398 [1:56:21<135:20:31, 47.56s/it]                                                         {'loss': 1.1669, 'learning_rate': 8.58974358974359e-06, 'epoch': 0.04}
  1%|â–         | 153/10398 [1:56:21<135:20:31, 47.56s/it]  1%|â–         | 154/10398 [1:57:08<135:12:07, 47.51s/it]                                                         {'loss': 1.0532, 'learning_rate': 8.653846153846155e-06, 'epoch': 0.04}
  1%|â–         | 154/10398 [1:57:08<135:12:07, 47.51s/it]  1%|â–         | 155/10398 [1:57:56<135:04:30, 47.47s/it]                                                         {'loss': 1.1768, 'learning_rate': 8.717948717948719e-06, 'epoch': 0.04}
  1%|â–         | 155/10398 [1:57:56<135:04:30, 47.47s/it]  2%|â–         | 156/10398 [1:58:43<134:55:13, 47.42s/it]                                                         {'loss': 1.1402, 'learning_rate': 8.782051282051283e-06, 'epoch': 0.04}
  2%|â–         | 156/10398 [1:58:43<134:55:13, 47.42s/it]  2%|â–         | 157/10398 [1:59:30<134:53:12, 47.42s/it]                                                         {'loss': 1.2365, 'learning_rate': 8.846153846153847e-06, 'epoch': 0.05}
  2%|â–         | 157/10398 [1:59:30<134:53:12, 47.42s/it]  2%|â–         | 158/10398 [2:00:18<134:55:19, 47.43s/it]                                                         {'loss': 1.0821, 'learning_rate': 8.910256410256411e-06, 'epoch': 0.05}
  2%|â–         | 158/10398 [2:00:18<134:55:19, 47.43s/it]  2%|â–         | 159/10398 [2:01:05<135:02:01, 47.48s/it]                                                         {'loss': 1.1101, 'learning_rate': 8.974358974358976e-06, 'epoch': 0.05}
  2%|â–         | 159/10398 [2:01:05<135:02:01, 47.48s/it]  2%|â–         | 160/10398 [2:01:53<135:16:23, 47.57s/it]                                                         {'loss': 0.961, 'learning_rate': 9.03846153846154e-06, 'epoch': 0.05}
  2%|â–         | 160/10398 [2:01:53<135:16:23, 47.57s/it]  2%|â–         | 161/10398 [2:02:41<135:01:55, 47.49s/it]                                                         {'loss': 1.0371, 'learning_rate': 9.102564102564104e-06, 'epoch': 0.05}
  2%|â–         | 161/10398 [2:02:41<135:01:55, 47.49s/it]  2%|â–         | 162/10398 [2:03:28<135:02:40, 47.50s/it]                                                         {'loss': 1.2447, 'learning_rate': 9.166666666666666e-06, 'epoch': 0.05}
  2%|â–         | 162/10398 [2:03:28<135:02:40, 47.50s/it]  2%|â–         | 163/10398 [2:04:15<134:55:00, 47.45s/it]                                                         {'loss': 1.3352, 'learning_rate': 9.230769230769232e-06, 'epoch': 0.05}
  2%|â–         | 163/10398 [2:04:15<134:55:00, 47.45s/it]  2%|â–         | 164/10398 [2:05:03<134:56:48, 47.47s/it]                                                         {'loss': 1.3334, 'learning_rate': 9.294871794871796e-06, 'epoch': 0.05}
  2%|â–         | 164/10398 [2:05:03<134:56:48, 47.47s/it]  2%|â–         | 165/10398 [2:05:50<134:59:40, 47.49s/it]                                                         {'loss': 1.0663, 'learning_rate': 9.358974358974359e-06, 'epoch': 0.05}
  2%|â–         | 165/10398 [2:05:50<134:59:40, 47.49s/it]  2%|â–         | 166/10398 [2:06:38<134:58:30, 47.49s/it]                                                         {'loss': 1.0922, 'learning_rate': 9.423076923076923e-06, 'epoch': 0.05}
  2%|â–         | 166/10398 [2:06:38<134:58:30, 47.49s/it]  2%|â–         | 167/10398 [2:07:25<134:57:21, 47.49s/it]                                                         {'loss': 1.1573, 'learning_rate': 9.487179487179487e-06, 'epoch': 0.05}
  2%|â–         | 167/10398 [2:07:25<134:57:21, 47.49s/it]  2%|â–         | 168/10398 [2:08:13<134:44:53, 47.42s/it]                                                         {'loss': 1.0757, 'learning_rate': 9.551282051282053e-06, 'epoch': 0.05}
  2%|â–         | 168/10398 [2:08:13<134:44:53, 47.42s/it]  2%|â–         | 169/10398 [2:09:00<134:41:16, 47.40s/it]                                                         {'loss': 1.3504, 'learning_rate': 9.615384615384616e-06, 'epoch': 0.05}
  2%|â–         | 169/10398 [2:09:00<134:41:16, 47.40s/it]  2%|â–         | 170/10398 [2:09:47<134:39:14, 47.39s/it]                                                         {'loss': 1.1633, 'learning_rate': 9.67948717948718e-06, 'epoch': 0.05}
  2%|â–         | 170/10398 [2:09:47<134:39:14, 47.39s/it]  2%|â–         | 171/10398 [2:10:35<134:45:22, 47.44s/it]                                                         {'loss': 1.1804, 'learning_rate': 9.743589743589744e-06, 'epoch': 0.05}
  2%|â–         | 171/10398 [2:10:35<134:45:22, 47.44s/it]  2%|â–         | 172/10398 [2:11:22<134:36:16, 47.39s/it]                                                         {'loss': 1.1229, 'learning_rate': 9.807692307692308e-06, 'epoch': 0.05}
  2%|â–         | 172/10398 [2:11:22<134:36:16, 47.39s/it]  2%|â–         | 173/10398 [2:12:09<134:28:43, 47.35s/it]                                                         {'loss': 1.1391, 'learning_rate': 9.871794871794872e-06, 'epoch': 0.05}
  2%|â–         | 173/10398 [2:12:09<134:28:43, 47.35s/it]  2%|â–         | 174/10398 [2:12:57<134:47:01, 47.46s/it]                                                         {'loss': 1.1481, 'learning_rate': 9.935897435897437e-06, 'epoch': 0.05}
  2%|â–         | 174/10398 [2:12:57<134:47:01, 47.46s/it]  2%|â–         | 175/10398 [2:13:45<134:59:03, 47.53s/it]                                                         {'loss': 1.0844, 'learning_rate': 1e-05, 'epoch': 0.05}
  2%|â–         | 175/10398 [2:13:45<134:59:03, 47.53s/it]  2%|â–         | 176/10398 [2:14:32<134:43:53, 47.45s/it]                                                         {'loss': 1.1348, 'learning_rate': 1.0064102564102565e-05, 'epoch': 0.05}
  2%|â–         | 176/10398 [2:14:32<134:43:53, 47.45s/it]  2%|â–         | 177/10398 [2:15:20<134:45:34, 47.46s/it]                                                         {'loss': 0.8306, 'learning_rate': 1.012820512820513e-05, 'epoch': 0.05}
  2%|â–         | 177/10398 [2:15:20<134:45:34, 47.46s/it]  2%|â–         | 178/10398 [2:16:07<135:03:47, 47.58s/it]                                                         {'loss': 1.0161, 'learning_rate': 1.0192307692307692e-05, 'epoch': 0.05}
  2%|â–         | 178/10398 [2:16:07<135:03:47, 47.58s/it]  2%|â–         | 179/10398 [2:16:55<134:58:23, 47.55s/it]                                                         {'loss': 1.0531, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.05}
  2%|â–         | 179/10398 [2:16:55<134:58:23, 47.55s/it]  2%|â–         | 180/10398 [2:17:43<135:00:58, 47.57s/it]                                                         {'loss': 1.1092, 'learning_rate': 1.0320512820512822e-05, 'epoch': 0.05}
  2%|â–         | 180/10398 [2:17:43<135:00:58, 47.57s/it]  2%|â–         | 181/10398 [2:18:30<134:43:58, 47.47s/it]                                                         {'loss': 1.4891, 'learning_rate': 1.0384615384615386e-05, 'epoch': 0.05}
  2%|â–         | 181/10398 [2:18:30<134:43:58, 47.47s/it]  2%|â–         | 182/10398 [2:19:18<134:54:30, 47.54s/it]                                                         {'loss': 1.0661, 'learning_rate': 1.044871794871795e-05, 'epoch': 0.05}
  2%|â–         | 182/10398 [2:19:18<134:54:30, 47.54s/it]  2%|â–         | 183/10398 [2:20:05<134:53:04, 47.54s/it]                                                         {'loss': 1.0514, 'learning_rate': 1.0512820512820514e-05, 'epoch': 0.05}
  2%|â–         | 183/10398 [2:20:05<134:53:04, 47.54s/it]  2%|â–         | 184/10398 [2:20:52<134:40:18, 47.47s/it]                                                         {'loss': 1.2439, 'learning_rate': 1.0576923076923078e-05, 'epoch': 0.05}
  2%|â–         | 184/10398 [2:20:52<134:40:18, 47.47s/it]  2%|â–         | 185/10398 [2:21:40<134:28:36, 47.40s/it]                                                         {'loss': 1.063, 'learning_rate': 1.0641025641025643e-05, 'epoch': 0.05}
  2%|â–         | 185/10398 [2:21:40<134:28:36, 47.40s/it]  2%|â–         | 186/10398 [2:22:27<134:27:13, 47.40s/it]                                                         {'loss': 1.1185, 'learning_rate': 1.0705128205128205e-05, 'epoch': 0.05}
  2%|â–         | 186/10398 [2:22:27<134:27:13, 47.40s/it]  2%|â–         | 187/10398 [2:23:14<134:15:43, 47.34s/it]                                                         {'loss': 1.1337, 'learning_rate': 1.076923076923077e-05, 'epoch': 0.05}
  2%|â–         | 187/10398 [2:23:14<134:15:43, 47.34s/it]  2%|â–         | 188/10398 [2:24:02<134:20:35, 47.37s/it]                                                         {'loss': 1.0632, 'learning_rate': 1.0833333333333334e-05, 'epoch': 0.05}
  2%|â–         | 188/10398 [2:24:02<134:20:35, 47.37s/it]  2%|â–         | 189/10398 [2:24:49<134:34:27, 47.45s/it]                                                         {'loss': 1.4121, 'learning_rate': 1.0897435897435898e-05, 'epoch': 0.05}
  2%|â–         | 189/10398 [2:24:49<134:34:27, 47.45s/it]  2%|â–         | 190/10398 [2:25:37<134:40:05, 47.49s/it]                                                         {'loss': 1.1598, 'learning_rate': 1.0961538461538464e-05, 'epoch': 0.05}
  2%|â–         | 190/10398 [2:25:37<134:40:05, 47.49s/it]  2%|â–         | 191/10398 [2:26:24<134:39:41, 47.49s/it]                                                         {'loss': 1.1411, 'learning_rate': 1.1025641025641028e-05, 'epoch': 0.06}
  2%|â–         | 191/10398 [2:26:24<134:39:41, 47.49s/it]  2%|â–         | 192/10398 [2:27:12<134:40:47, 47.51s/it]                                                         {'loss': 1.1547, 'learning_rate': 1.1089743589743592e-05, 'epoch': 0.06}
  2%|â–         | 192/10398 [2:27:12<134:40:47, 47.51s/it]  2%|â–         | 193/10398 [2:27:59<134:35:46, 47.48s/it]                                                         {'loss': 1.2404, 'learning_rate': 1.1153846153846154e-05, 'epoch': 0.06}
  2%|â–         | 193/10398 [2:27:59<134:35:46, 47.48s/it]  2%|â–         | 194/10398 [2:28:47<134:49:10, 47.56s/it]                                                         {'loss': 1.0185, 'learning_rate': 1.1217948717948719e-05, 'epoch': 0.06}
  2%|â–         | 194/10398 [2:28:47<134:49:10, 47.56s/it]  2%|â–         | 195/10398 [2:29:35<134:51:02, 47.58s/it]                                                         {'loss': 0.9769, 'learning_rate': 1.1282051282051283e-05, 'epoch': 0.06}
  2%|â–         | 195/10398 [2:29:35<134:51:02, 47.58s/it]  2%|â–         | 196/10398 [2:30:22<134:51:45, 47.59s/it]                                                         {'loss': 1.064, 'learning_rate': 1.1346153846153847e-05, 'epoch': 0.06}
  2%|â–         | 196/10398 [2:30:22<134:51:45, 47.59s/it]  2%|â–         | 197/10398 [2:31:10<134:36:33, 47.50s/it]                                                         {'loss': 1.4404, 'learning_rate': 1.1410256410256411e-05, 'epoch': 0.06}
  2%|â–         | 197/10398 [2:31:10<134:36:33, 47.50s/it]  2%|â–         | 198/10398 [2:31:57<134:26:28, 47.45s/it]                                                         {'loss': 1.1116, 'learning_rate': 1.1474358974358974e-05, 'epoch': 0.06}
  2%|â–         | 198/10398 [2:31:57<134:26:28, 47.45s/it]  2%|â–         | 199/10398 [2:32:45<134:40:28, 47.54s/it]                                                         {'loss': 1.2805, 'learning_rate': 1.1538461538461538e-05, 'epoch': 0.06}
  2%|â–         | 199/10398 [2:32:45<134:40:28, 47.54s/it]  2%|â–         | 200/10398 [2:33:32<134:37:54, 47.53s/it]                                                         {'loss': 1.0096, 'learning_rate': 1.1602564102564104e-05, 'epoch': 0.06}
  2%|â–         | 200/10398 [2:33:32<134:37:54, 47.53s/it]  2%|â–         | 201/10398 [2:34:20<134:40:02, 47.54s/it]                                                         {'loss': 1.105, 'learning_rate': 1.1666666666666668e-05, 'epoch': 0.06}
  2%|â–         | 201/10398 [2:34:20<134:40:02, 47.54s/it]  2%|â–         | 202/10398 [2:35:07<134:39:25, 47.54s/it]                                                         {'loss': 1.1809, 'learning_rate': 1.1730769230769232e-05, 'epoch': 0.06}
  2%|â–         | 202/10398 [2:35:07<134:39:25, 47.54s/it]  2%|â–         | 203/10398 [2:35:55<134:40:54, 47.56s/it]                                                         {'loss': 0.9532, 'learning_rate': 1.1794871794871796e-05, 'epoch': 0.06}
  2%|â–         | 203/10398 [2:35:55<134:40:54, 47.56s/it]  2%|â–         | 204/10398 [2:36:42<134:41:04, 47.56s/it]                                                         {'loss': 1.0639, 'learning_rate': 1.185897435897436e-05, 'epoch': 0.06}
  2%|â–         | 204/10398 [2:36:42<134:41:04, 47.56s/it]  2%|â–         | 205/10398 [2:37:30<134:59:46, 47.68s/it]                                                         {'loss': 0.8705, 'learning_rate': 1.1923076923076925e-05, 'epoch': 0.06}
  2%|â–         | 205/10398 [2:37:30<134:59:46, 47.68s/it]  2%|â–         | 206/10398 [2:38:18<134:41:40, 47.58s/it]                                                         {'loss': 1.1015, 'learning_rate': 1.1987179487179487e-05, 'epoch': 0.06}
  2%|â–         | 206/10398 [2:38:18<134:41:40, 47.58s/it]  2%|â–         | 207/10398 [2:39:05<134:22:06, 47.47s/it]                                                         {'loss': 1.1416, 'learning_rate': 1.2051282051282051e-05, 'epoch': 0.06}
  2%|â–         | 207/10398 [2:39:05<134:22:06, 47.47s/it]  2%|â–         | 208/10398 [2:39:52<134:13:27, 47.42s/it]                                                         {'loss': 1.3697, 'learning_rate': 1.2115384615384615e-05, 'epoch': 0.06}
  2%|â–         | 208/10398 [2:39:52<134:13:27, 47.42s/it]  2%|â–         | 209/10398 [2:40:40<134:01:48, 47.36s/it]                                                         {'loss': 1.0939, 'learning_rate': 1.217948717948718e-05, 'epoch': 0.06}
  2%|â–         | 209/10398 [2:40:40<134:01:48, 47.36s/it]  2%|â–         | 210/10398 [2:41:27<133:59:15, 47.35s/it]                                                         {'loss': 1.205, 'learning_rate': 1.2243589743589746e-05, 'epoch': 0.06}
  2%|â–         | 210/10398 [2:41:27<133:59:15, 47.35s/it]  2%|â–         | 211/10398 [2:42:14<133:58:10, 47.34s/it]                                                         {'loss': 1.2043, 'learning_rate': 1.230769230769231e-05, 'epoch': 0.06}
  2%|â–         | 211/10398 [2:42:14<133:58:10, 47.34s/it]  2%|â–         | 212/10398 [2:43:02<133:57:26, 47.34s/it]                                                         {'loss': 1.1443, 'learning_rate': 1.2371794871794874e-05, 'epoch': 0.06}
  2%|â–         | 212/10398 [2:43:02<133:57:26, 47.34s/it]  2%|â–         | 213/10398 [2:43:49<134:06:50, 47.40s/it]                                                         {'loss': 0.8277, 'learning_rate': 1.2435897435897436e-05, 'epoch': 0.06}
  2%|â–         | 213/10398 [2:43:49<134:06:50, 47.40s/it]  2%|â–         | 214/10398 [2:44:37<134:17:53, 47.47s/it]                                                         {'loss': 1.2344, 'learning_rate': 1.25e-05, 'epoch': 0.06}
  2%|â–         | 214/10398 [2:44:37<134:17:53, 47.47s/it]  2%|â–         | 215/10398 [2:45:24<134:24:29, 47.52s/it]                                                         {'loss': 0.881, 'learning_rate': 1.2564102564102565e-05, 'epoch': 0.06}
  2%|â–         | 215/10398 [2:45:24<134:24:29, 47.52s/it]  2%|â–         | 216/10398 [2:46:12<134:24:41, 47.52s/it]                                                         {'loss': 1.2412, 'learning_rate': 1.2628205128205129e-05, 'epoch': 0.06}
  2%|â–         | 216/10398 [2:46:12<134:24:41, 47.52s/it]  2%|â–         | 217/10398 [2:46:59<134:29:56, 47.56s/it]                                                         {'loss': 1.0409, 'learning_rate': 1.2692307692307693e-05, 'epoch': 0.06}
  2%|â–         | 217/10398 [2:46:59<134:29:56, 47.56s/it]  2%|â–         | 218/10398 [2:47:47<134:32:00, 47.58s/it]                                                         {'loss': 1.0151, 'learning_rate': 1.2756410256410257e-05, 'epoch': 0.06}
  2%|â–         | 218/10398 [2:47:47<134:32:00, 47.58s/it]  2%|â–         | 219/10398 [2:48:35<134:22:31, 47.52s/it]                                                         {'loss': 1.1198, 'learning_rate': 1.2820512820512823e-05, 'epoch': 0.06}
  2%|â–         | 219/10398 [2:48:35<134:22:31, 47.52s/it]  2%|â–         | 220/10398 [2:49:22<134:25:42, 47.55s/it]                                                         {'loss': 1.1515, 'learning_rate': 1.2884615384615386e-05, 'epoch': 0.06}
  2%|â–         | 220/10398 [2:49:22<134:25:42, 47.55s/it]  2%|â–         | 221/10398 [2:50:10<134:26:01, 47.55s/it]                                                         {'loss': 1.1297, 'learning_rate': 1.294871794871795e-05, 'epoch': 0.06}
  2%|â–         | 221/10398 [2:50:10<134:26:01, 47.55s/it]  2%|â–         | 222/10398 [2:50:57<134:25:04, 47.55s/it]                                                         {'loss': 1.0072, 'learning_rate': 1.3012820512820514e-05, 'epoch': 0.06}
  2%|â–         | 222/10398 [2:50:57<134:25:04, 47.55s/it]  2%|â–         | 223/10398 [2:51:45<134:20:21, 47.53s/it]                                                         {'loss': 1.3467, 'learning_rate': 1.3076923076923078e-05, 'epoch': 0.06}
  2%|â–         | 223/10398 [2:51:45<134:20:21, 47.53s/it]  2%|â–         | 224/10398 [2:52:32<134:18:34, 47.52s/it]                                                         {'loss': 1.2017, 'learning_rate': 1.3141025641025642e-05, 'epoch': 0.06}
  2%|â–         | 224/10398 [2:52:32<134:18:34, 47.52s/it]  2%|â–         | 225/10398 [2:53:20<134:26:27, 47.58s/it]                                                         {'loss': 1.0858, 'learning_rate': 1.3205128205128207e-05, 'epoch': 0.06}
  2%|â–         | 225/10398 [2:53:20<134:26:27, 47.58s/it]  2%|â–         | 226/10398 [2:54:07<134:13:44, 47.51s/it]                                                         {'loss': 1.1498, 'learning_rate': 1.3269230769230769e-05, 'epoch': 0.07}
  2%|â–         | 226/10398 [2:54:07<134:13:44, 47.51s/it]  2%|â–         | 227/10398 [2:54:55<134:18:35, 47.54s/it]                                                         {'loss': 1.3342, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.07}
  2%|â–         | 227/10398 [2:54:55<134:18:35, 47.54s/it]  2%|â–         | 228/10398 [2:55:42<134:12:16, 47.51s/it]                                                         {'loss': 1.0539, 'learning_rate': 1.3397435897435897e-05, 'epoch': 0.07}
  2%|â–         | 228/10398 [2:55:42<134:12:16, 47.51s/it]  2%|â–         | 229/10398 [2:56:30<133:56:26, 47.42s/it]                                                         {'loss': 1.3268, 'learning_rate': 1.3461538461538463e-05, 'epoch': 0.07}
  2%|â–         | 229/10398 [2:56:30<133:56:26, 47.42s/it]  2%|â–         | 230/10398 [2:57:17<133:45:23, 47.36s/it]                                                         {'loss': 1.0541, 'learning_rate': 1.3525641025641028e-05, 'epoch': 0.07}
  2%|â–         | 230/10398 [2:57:17<133:45:23, 47.36s/it]  2%|â–         | 231/10398 [2:58:04<133:58:31, 47.44s/it]                                                         {'loss': 1.2756, 'learning_rate': 1.3589743589743592e-05, 'epoch': 0.07}
  2%|â–         | 231/10398 [2:58:04<133:58:31, 47.44s/it]  2%|â–         | 232/10398 [2:58:52<133:53:14, 47.41s/it]                                                         {'loss': 0.9985, 'learning_rate': 1.3653846153846156e-05, 'epoch': 0.07}
  2%|â–         | 232/10398 [2:58:52<133:53:14, 47.41s/it]  2%|â–         | 233/10398 [2:59:39<133:53:42, 47.42s/it]                                                         {'loss': 1.02, 'learning_rate': 1.3717948717948718e-05, 'epoch': 0.07}
  2%|â–         | 233/10398 [2:59:39<133:53:42, 47.42s/it]  2%|â–         | 234/10398 [3:00:27<134:01:31, 47.47s/it]                                                         {'loss': 1.3377, 'learning_rate': 1.3782051282051283e-05, 'epoch': 0.07}
  2%|â–         | 234/10398 [3:00:27<134:01:31, 47.47s/it]  2%|â–         | 235/10398 [3:01:14<134:04:08, 47.49s/it]                                                         {'loss': 1.4062, 'learning_rate': 1.3846153846153847e-05, 'epoch': 0.07}
  2%|â–         | 235/10398 [3:01:14<134:04:08, 47.49s/it]  2%|â–         | 236/10398 [3:02:02<133:57:42, 47.46s/it]                                                         {'loss': 1.101, 'learning_rate': 1.3910256410256411e-05, 'epoch': 0.07}
  2%|â–         | 236/10398 [3:02:02<133:57:42, 47.46s/it]  2%|â–         | 237/10398 [3:02:49<133:53:44, 47.44s/it]                                                         {'loss': 1.0668, 'learning_rate': 1.3974358974358975e-05, 'epoch': 0.07}
  2%|â–         | 237/10398 [3:02:49<133:53:44, 47.44s/it]  2%|â–         | 238/10398 [3:03:37<133:54:43, 47.45s/it]                                                         {'loss': 1.2317, 'learning_rate': 1.403846153846154e-05, 'epoch': 0.07}
  2%|â–         | 238/10398 [3:03:37<133:54:43, 47.45s/it]  2%|â–         | 239/10398 [3:04:24<133:53:02, 47.44s/it]                                                         {'loss': 1.0781, 'learning_rate': 1.4102564102564105e-05, 'epoch': 0.07}
  2%|â–         | 239/10398 [3:04:24<133:53:02, 47.44s/it]  2%|â–         | 240/10398 [3:05:11<133:47:54, 47.42s/it]                                                         {'loss': 1.2154, 'learning_rate': 1.416666666666667e-05, 'epoch': 0.07}
  2%|â–         | 240/10398 [3:05:11<133:47:54, 47.42s/it]  2%|â–         | 241/10398 [3:05:59<133:54:13, 47.46s/it]                                                         {'loss': 1.2547, 'learning_rate': 1.4230769230769232e-05, 'epoch': 0.07}
  2%|â–         | 241/10398 [3:05:59<133:54:13, 47.46s/it]  2%|â–         | 242/10398 [3:06:46<133:46:59, 47.42s/it]                                                         {'loss': 1.1684, 'learning_rate': 1.4294871794871796e-05, 'epoch': 0.07}
  2%|â–         | 242/10398 [3:06:46<133:46:59, 47.42s/it]  2%|â–         | 243/10398 [3:07:34<133:52:09, 47.46s/it]                                                         {'loss': 0.9188, 'learning_rate': 1.435897435897436e-05, 'epoch': 0.07}
  2%|â–         | 243/10398 [3:07:34<133:52:09, 47.46s/it]  2%|â–         | 244/10398 [3:08:21<133:47:18, 47.43s/it]                                                         {'loss': 0.9031, 'learning_rate': 1.4423076923076924e-05, 'epoch': 0.07}
  2%|â–         | 244/10398 [3:08:21<133:47:18, 47.43s/it]  2%|â–         | 245/10398 [3:09:09<133:47:10, 47.44s/it]                                                         {'loss': 1.1144, 'learning_rate': 1.4487179487179489e-05, 'epoch': 0.07}
  2%|â–         | 245/10398 [3:09:09<133:47:10, 47.44s/it]  2%|â–         | 246/10398 [3:09:56<133:45:06, 47.43s/it]                                                         {'loss': 1.0776, 'learning_rate': 1.4551282051282051e-05, 'epoch': 0.07}
  2%|â–         | 246/10398 [3:09:56<133:45:06, 47.43s/it]  2%|â–         | 247/10398 [3:10:43<133:46:58, 47.45s/it]                                                         {'loss': 1.342, 'learning_rate': 1.4615384615384615e-05, 'epoch': 0.07}
  2%|â–         | 247/10398 [3:10:43<133:46:58, 47.45s/it]  2%|â–         | 248/10398 [3:11:31<133:40:56, 47.41s/it]                                                         {'loss': 1.1811, 'learning_rate': 1.467948717948718e-05, 'epoch': 0.07}
  2%|â–         | 248/10398 [3:11:31<133:40:56, 47.41s/it]  2%|â–         | 249/10398 [3:12:19<133:56:05, 47.51s/it]                                                         {'loss': 0.9041, 'learning_rate': 1.4743589743589745e-05, 'epoch': 0.07}
  2%|â–         | 249/10398 [3:12:19<133:56:05, 47.51s/it]  2%|â–         | 250/10398 [3:13:06<134:11:22, 47.60s/it]                                                         {'loss': 1.2059, 'learning_rate': 1.480769230769231e-05, 'epoch': 0.07}
  2%|â–         | 250/10398 [3:13:06<134:11:22, 47.60s/it]  2%|â–         | 251/10398 [3:13:54<134:25:53, 47.69s/it]                                                         {'loss': 1.1369, 'learning_rate': 1.4871794871794874e-05, 'epoch': 0.07}
  2%|â–         | 251/10398 [3:13:54<134:25:53, 47.69s/it]  2%|â–         | 252/10398 [3:14:42<134:32:31, 47.74s/it]                                                         {'loss': 1.1348, 'learning_rate': 1.4935897435897438e-05, 'epoch': 0.07}
  2%|â–         | 252/10398 [3:14:42<134:32:31, 47.74s/it]  2%|â–         | 253/10398 [3:15:30<134:40:08, 47.79s/it]                                                         {'loss': 1.0757, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.07}
  2%|â–         | 253/10398 [3:15:30<134:40:08, 47.79s/it]  2%|â–         | 254/10398 [3:16:17<134:22:50, 47.69s/it]                                                         {'loss': 1.0952, 'learning_rate': 1.5064102564102565e-05, 'epoch': 0.07}
  2%|â–         | 254/10398 [3:16:17<134:22:50, 47.69s/it]  2%|â–         | 255/10398 [3:17:05<134:32:13, 47.75s/it]                                                         {'loss': 1.1245, 'learning_rate': 1.5128205128205129e-05, 'epoch': 0.07}
  2%|â–         | 255/10398 [3:17:05<134:32:13, 47.75s/it]  2%|â–         | 256/10398 [3:17:53<134:42:28, 47.82s/it]                                                         {'loss': 1.1384, 'learning_rate': 1.5192307692307693e-05, 'epoch': 0.07}
  2%|â–         | 256/10398 [3:17:53<134:42:28, 47.82s/it]  2%|â–         | 257/10398 [3:18:41<134:51:02, 47.87s/it]                                                         {'loss': 0.9083, 'learning_rate': 1.5256410256410257e-05, 'epoch': 0.07}
  2%|â–         | 257/10398 [3:18:41<134:51:02, 47.87s/it]  2%|â–         | 258/10398 [3:19:29<135:00:04, 47.93s/it]                                                         {'loss': 1.132, 'learning_rate': 1.5320512820512823e-05, 'epoch': 0.07}
  2%|â–         | 258/10398 [3:19:29<135:00:04, 47.93s/it]  2%|â–         | 259/10398 [3:20:17<134:41:51, 47.83s/it]                                                         {'loss': 1.0662, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.07}
  2%|â–         | 259/10398 [3:20:17<134:41:51, 47.83s/it]  3%|â–Ž         | 260/10398 [3:21:05<134:41:52, 47.83s/it]                                                         {'loss': 1.1787, 'learning_rate': 1.544871794871795e-05, 'epoch': 0.07}
  3%|â–Ž         | 260/10398 [3:21:05<134:41:52, 47.83s/it]  3%|â–Ž         | 261/10398 [3:21:53<134:48:16, 47.87s/it]                                                         {'loss': 1.2247, 'learning_rate': 1.5512820512820516e-05, 'epoch': 0.08}
  3%|â–Ž         | 261/10398 [3:21:53<134:48:16, 47.87s/it]  3%|â–Ž         | 262/10398 [3:22:41<134:58:05, 47.94s/it]                                                         {'loss': 1.3449, 'learning_rate': 1.557692307692308e-05, 'epoch': 0.08}
  3%|â–Ž         | 262/10398 [3:22:41<134:58:05, 47.94s/it]  3%|â–Ž         | 263/10398 [3:23:29<134:57:41, 47.94s/it]                                                         {'loss': 1.0421, 'learning_rate': 1.5641025641025644e-05, 'epoch': 0.08}
  3%|â–Ž         | 263/10398 [3:23:29<134:57:41, 47.94s/it]  3%|â–Ž         | 264/10398 [3:24:17<134:54:35, 47.93s/it]                                                         {'loss': 1.1609, 'learning_rate': 1.5705128205128205e-05, 'epoch': 0.08}
  3%|â–Ž         | 264/10398 [3:24:17<134:54:35, 47.93s/it]  3%|â–Ž         | 265/10398 [3:25:04<134:39:18, 47.84s/it]                                                         {'loss': 1.2967, 'learning_rate': 1.576923076923077e-05, 'epoch': 0.08}
  3%|â–Ž         | 265/10398 [3:25:04<134:39:18, 47.84s/it]  3%|â–Ž         | 266/10398 [3:25:52<134:43:26, 47.87s/it]                                                         {'loss': 1.1641, 'learning_rate': 1.5833333333333333e-05, 'epoch': 0.08}
  3%|â–Ž         | 266/10398 [3:25:52<134:43:26, 47.87s/it]  3%|â–Ž         | 267/10398 [3:26:40<134:35:40, 47.83s/it]                                                         {'loss': 1.2701, 'learning_rate': 1.5897435897435897e-05, 'epoch': 0.08}
  3%|â–Ž         | 267/10398 [3:26:40<134:35:40, 47.83s/it]  3%|â–Ž         | 268/10398 [3:27:29<135:27:22, 48.14s/it]                                                         {'loss': 1.1395, 'learning_rate': 1.5961538461538465e-05, 'epoch': 0.08}
  3%|â–Ž         | 268/10398 [3:27:29<135:27:22, 48.14s/it]  3%|â–Ž         | 269/10398 [3:28:18<136:09:16, 48.39s/it]                                                         {'loss': 1.1076, 'learning_rate': 1.602564102564103e-05, 'epoch': 0.08}
  3%|â–Ž         | 269/10398 [3:28:18<136:09:16, 48.39s/it]  3%|â–Ž         | 270/10398 [3:29:07<136:24:17, 48.49s/it]                                                         {'loss': 1.141, 'learning_rate': 1.6089743589743593e-05, 'epoch': 0.08}
  3%|â–Ž         | 270/10398 [3:29:07<136:24:17, 48.49s/it]  3%|â–Ž         | 271/10398 [3:29:55<136:34:31, 48.55s/it]                                                         {'loss': 1.229, 'learning_rate': 1.6153846153846154e-05, 'epoch': 0.08}
  3%|â–Ž         | 271/10398 [3:29:55<136:34:31, 48.55s/it]  3%|â–Ž         | 272/10398 [3:30:44<136:46:17, 48.63s/it]                                                         {'loss': 1.1607, 'learning_rate': 1.6217948717948718e-05, 'epoch': 0.08}
  3%|â–Ž         | 272/10398 [3:30:44<136:46:17, 48.63s/it]  3%|â–Ž         | 273/10398 [3:31:33<137:03:31, 48.73s/it]                                                         {'loss': 1.3533, 'learning_rate': 1.6282051282051282e-05, 'epoch': 0.08}
  3%|â–Ž         | 273/10398 [3:31:33<137:03:31, 48.73s/it]  3%|â–Ž         | 274/10398 [3:32:22<137:07:43, 48.76s/it]                                                         {'loss': 1.0984, 'learning_rate': 1.6346153846153847e-05, 'epoch': 0.08}
  3%|â–Ž         | 274/10398 [3:32:22<137:07:43, 48.76s/it]  3%|â–Ž         | 275/10398 [3:33:11<137:08:01, 48.77s/it]                                                         {'loss': 0.8776, 'learning_rate': 1.641025641025641e-05, 'epoch': 0.08}
  3%|â–Ž         | 275/10398 [3:33:11<137:08:01, 48.77s/it]  3%|â–Ž         | 276/10398 [3:33:59<137:05:20, 48.76s/it]                                                         {'loss': 1.0225, 'learning_rate': 1.6474358974358975e-05, 'epoch': 0.08}
  3%|â–Ž         | 276/10398 [3:33:59<137:05:20, 48.76s/it]  3%|â–Ž         | 277/10398 [3:34:48<136:54:52, 48.70s/it]                                                         {'loss': 1.1209, 'learning_rate': 1.653846153846154e-05, 'epoch': 0.08}
  3%|â–Ž         | 277/10398 [3:34:48<136:54:52, 48.70s/it]  3%|â–Ž         | 278/10398 [3:35:37<136:53:13, 48.70s/it]                                                         {'loss': 1.3883, 'learning_rate': 1.6602564102564103e-05, 'epoch': 0.08}
  3%|â–Ž         | 278/10398 [3:35:37<136:53:13, 48.70s/it]  3%|â–Ž         | 279/10398 [3:36:25<136:55:02, 48.71s/it]                                                         {'loss': 1.1549, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.08}
  3%|â–Ž         | 279/10398 [3:36:25<136:55:02, 48.71s/it]  3%|â–Ž         | 280/10398 [3:37:14<136:49:39, 48.68s/it]                                                         {'loss': 1.377, 'learning_rate': 1.673076923076923e-05, 'epoch': 0.08}
  3%|â–Ž         | 280/10398 [3:37:14<136:49:39, 48.68s/it]  3%|â–Ž         | 281/10398 [3:38:02<136:35:45, 48.61s/it]                                                         {'loss': 1.0129, 'learning_rate': 1.6794871794871796e-05, 'epoch': 0.08}
  3%|â–Ž         | 281/10398 [3:38:02<136:35:45, 48.61s/it]  3%|â–Ž         | 282/10398 [3:38:51<136:38:18, 48.63s/it]                                                         {'loss': 0.999, 'learning_rate': 1.685897435897436e-05, 'epoch': 0.08}
  3%|â–Ž         | 282/10398 [3:38:51<136:38:18, 48.63s/it]  3%|â–Ž         | 283/10398 [3:39:40<136:54:35, 48.73s/it]                                                         {'loss': 1.1641, 'learning_rate': 1.6923076923076924e-05, 'epoch': 0.08}
  3%|â–Ž         | 283/10398 [3:39:40<136:54:35, 48.73s/it]  3%|â–Ž         | 284/10398 [3:40:29<136:42:00, 48.66s/it]                                                         {'loss': 0.9423, 'learning_rate': 1.698717948717949e-05, 'epoch': 0.08}
  3%|â–Ž         | 284/10398 [3:40:29<136:42:00, 48.66s/it]  3%|â–Ž         | 285/10398 [3:41:17<136:43:19, 48.67s/it]                                                         {'loss': 0.9836, 'learning_rate': 1.7051282051282053e-05, 'epoch': 0.08}
  3%|â–Ž         | 285/10398 [3:41:17<136:43:19, 48.67s/it]  3%|â–Ž         | 286/10398 [3:42:06<136:21:12, 48.54s/it]                                                         {'loss': 0.9518, 'learning_rate': 1.7115384615384617e-05, 'epoch': 0.08}
  3%|â–Ž         | 286/10398 [3:42:06<136:21:12, 48.54s/it]  3%|â–Ž         | 287/10398 [3:42:54<136:35:42, 48.63s/it]                                                         {'loss': 1.2938, 'learning_rate': 1.717948717948718e-05, 'epoch': 0.08}
  3%|â–Ž         | 287/10398 [3:42:54<136:35:42, 48.63s/it]  3%|â–Ž         | 288/10398 [3:43:43<136:49:20, 48.72s/it]                                                         {'loss': 1.1779, 'learning_rate': 1.7243589743589745e-05, 'epoch': 0.08}
  3%|â–Ž         | 288/10398 [3:43:43<136:49:20, 48.72s/it]  3%|â–Ž         | 289/10398 [3:44:32<136:34:15, 48.64s/it]                                                         {'loss': 1.1029, 'learning_rate': 1.730769230769231e-05, 'epoch': 0.08}
  3%|â–Ž         | 289/10398 [3:44:32<136:34:15, 48.64s/it]  3%|â–Ž         | 290/10398 [3:45:21<136:41:22, 48.68s/it]                                                         {'loss': 1.035, 'learning_rate': 1.7371794871794873e-05, 'epoch': 0.08}
  3%|â–Ž         | 290/10398 [3:45:21<136:41:22, 48.68s/it]  3%|â–Ž         | 291/10398 [3:46:09<136:32:12, 48.63s/it]                                                         {'loss': 1.1762, 'learning_rate': 1.7435897435897438e-05, 'epoch': 0.08}
  3%|â–Ž         | 291/10398 [3:46:09<136:32:12, 48.63s/it]  3%|â–Ž         | 292/10398 [3:46:58<136:34:48, 48.65s/it]                                                         {'loss': 1.0619, 'learning_rate': 1.7500000000000002e-05, 'epoch': 0.08}
  3%|â–Ž         | 292/10398 [3:46:58<136:34:48, 48.65s/it]  3%|â–Ž         | 293/10398 [3:47:47<136:39:42, 48.69s/it]                                                         {'loss': 1.1214, 'learning_rate': 1.7564102564102566e-05, 'epoch': 0.08}
  3%|â–Ž         | 293/10398 [3:47:47<136:39:42, 48.69s/it]  3%|â–Ž         | 294/10398 [3:48:35<136:48:04, 48.74s/it]                                                         {'loss': 1.2976, 'learning_rate': 1.762820512820513e-05, 'epoch': 0.08}
  3%|â–Ž         | 294/10398 [3:48:35<136:48:04, 48.74s/it]  3%|â–Ž         | 295/10398 [3:49:24<136:57:57, 48.81s/it]                                                         {'loss': 1.106, 'learning_rate': 1.7692307692307694e-05, 'epoch': 0.09}
  3%|â–Ž         | 295/10398 [3:49:24<136:57:57, 48.81s/it]  3%|â–Ž         | 296/10398 [3:50:13<136:48:59, 48.76s/it]                                                         {'loss': 1.0634, 'learning_rate': 1.775641025641026e-05, 'epoch': 0.09}
  3%|â–Ž         | 296/10398 [3:50:13<136:48:59, 48.76s/it]  3%|â–Ž         | 297/10398 [3:51:02<136:42:17, 48.72s/it]                                                         {'loss': 1.1529, 'learning_rate': 1.7820512820512823e-05, 'epoch': 0.09}
  3%|â–Ž         | 297/10398 [3:51:02<136:42:17, 48.72s/it]  3%|â–Ž         | 298/10398 [3:51:50<136:41:08, 48.72s/it]                                                         {'loss': 1.1574, 'learning_rate': 1.7884615384615387e-05, 'epoch': 0.09}
  3%|â–Ž         | 298/10398 [3:51:50<136:41:08, 48.72s/it]  3%|â–Ž         | 299/10398 [3:52:39<136:34:18, 48.68s/it]                                                         {'loss': 1.3691, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.09}
  3%|â–Ž         | 299/10398 [3:52:39<136:34:18, 48.68s/it]  3%|â–Ž         | 300/10398 [3:53:28<136:38:01, 48.71s/it]                                                         {'loss': 1.3246, 'learning_rate': 1.8012820512820515e-05, 'epoch': 0.09}
  3%|â–Ž         | 300/10398 [3:53:28<136:38:01, 48.71s/it]  3%|â–Ž         | 301/10398 [3:54:17<136:50:28, 48.79s/it]                                                         {'loss': 1.1716, 'learning_rate': 1.807692307692308e-05, 'epoch': 0.09}
  3%|â–Ž         | 301/10398 [3:54:17<136:50:28, 48.79s/it]  3%|â–Ž         | 302/10398 [3:55:06<136:54:50, 48.82s/it]                                                         {'loss': 1.0022, 'learning_rate': 1.8141025641025644e-05, 'epoch': 0.09}
  3%|â–Ž         | 302/10398 [3:55:06<136:54:50, 48.82s/it]  3%|â–Ž         | 303/10398 [3:55:54<136:54:22, 48.82s/it]                                                         {'loss': 1.1441, 'learning_rate': 1.8205128205128208e-05, 'epoch': 0.09}
  3%|â–Ž         | 303/10398 [3:55:54<136:54:22, 48.82s/it]  3%|â–Ž         | 304/10398 [3:56:43<136:42:53, 48.76s/it]                                                         {'loss': 1.069, 'learning_rate': 1.826923076923077e-05, 'epoch': 0.09}
  3%|â–Ž         | 304/10398 [3:56:43<136:42:53, 48.76s/it]  3%|â–Ž         | 305/10398 [3:57:32<136:44:31, 48.77s/it]                                                         {'loss': 1.0137, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.09}
  3%|â–Ž         | 305/10398 [3:57:32<136:44:31, 48.77s/it]WARNING:torch.distributed.elastic.agent.server.api:Received 1 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 20549 closing signal SIGHUP
Traceback (most recent call last):
  File "/home/namz2/.conda/envs/alpaca/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 241, in launch_agent
    result = agent.run()
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 723, in run
    result = self._invoke_run(role)
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 864, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/namz2/.conda/envs/alpaca/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 20492 got signal: 1
